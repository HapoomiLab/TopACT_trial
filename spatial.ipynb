{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Classes and methods for array-based spatial transcriptomics analysis.\"\"\"\n",
    "\n",
    "import itertools\n",
    "from typing import Iterable, Iterator, Sequence, cast\n",
    "from multiprocessing import Process, Queue\n",
    "from warnings import simplefilter\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from scipy import sparse\n",
    "from countdata import CountTable\n",
    "from classifier import Classifier\n",
    "import densetools\n",
    "\n",
    "\n",
    "def combine_coords(coords: Iterable[int]) -> str:\n",
    "    \"\"\"Combines a tuple of ints into a unique string identifier.\"\"\"\n",
    "    return ','.join(map(str, coords))\n",
    "\n",
    "\n",
    "def split_coords(ident: str) -> tuple[int, ...]:\n",
    "    \"\"\"Splits a unique identifier into its corresponding coordinates.\n",
    "\n",
    "    Args:\n",
    "        ident: A string of the form '{x1},{x2},...,{xn}'.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of integers (x1, x2, ..., xn).\n",
    "    \"\"\"\n",
    "    return tuple(map(int, ident.split(','))) if ident else ()\n",
    "\n",
    "\n",
    "def first_coord(ident: str) -> int:\n",
    "    \"\"\"Obtains the first coordinate from a unique identifier.\n",
    "\n",
    "    Args:\n",
    "        ident: A string of the form '{x1},{x2},...,{xn}' where n>=1.\n",
    "\n",
    "    Returns:\n",
    "        The integer x1.\n",
    "    \"\"\"\n",
    "    return split_coords(ident)[0]\n",
    "\n",
    "\n",
    "def second_coord(ident: str) -> int:\n",
    "    \"\"\"Obtains the first coordinate from a unique identifier.\n",
    "\n",
    "    Args:\n",
    "        ident: A string of the form '{x1},{x2},...,{xn}' where n >= 2.\n",
    "\n",
    "    Returns:\n",
    "        The integer x2.\n",
    "    \"\"\"\n",
    "    return split_coords(ident)[1]\n",
    "\n",
    "\n",
    "def cartesian_product(x: npt.ArrayLike, y: npt.ArrayLike) -> npt.NDArray:\n",
    "    \"\"\"Computes the cartesian products of two 1-d vectors.\n",
    "\n",
    "    Args:\n",
    "        x: The first vector\n",
    "        y: The second vector\n",
    "\n",
    "    Returns:\n",
    "        An array of shape (len(x) * len(y), 2) whose rows are precisely all\n",
    "        possible tuples with first value in x and second value in y.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return np.transpose([np.tile(x, len(y)),\n",
    "                         np.repeat(y, len(x))])\n",
    "\n",
    "\n",
    "def square_nbhd(point: tuple[int, int],\n",
    "                scale: int,\n",
    "                x_range: tuple[int, int],\n",
    "                y_range: tuple[int, int]\n",
    "                ) -> Iterator[tuple[int, int]]:\n",
    "    \"\"\"All coordinates in a square neighbourhood about a point.\n",
    "\n",
    "    Args:\n",
    "        point: the (x,y) coordinates of the point\n",
    "        scale: the radius of the square\n",
    "        x_range: the least and greatest acceptable x values\n",
    "        y_range: the least and greated acceptable y values\n",
    "\n",
    "    Yields:\n",
    "        All tuples (i,j) satisfying the following:\n",
    "            - x_range[0] <= i <= x_range[1]\n",
    "            - y_range[0] <= j <= y_range[1]\n",
    "            - d(x,i) <= scale\n",
    "            - d(y,j) <= scale\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    x_min, x_max = x_range\n",
    "    y_min, y_max = y_range\n",
    "    x_min = max(x_min, x - scale)\n",
    "    x_max = min(x_max, x + scale)\n",
    "    y_min = max(y_min, y - scale)\n",
    "    y_max = min(y_max, y + scale)\n",
    "    return itertools.product(range(x_min, x_max+1), range(y_min, y_max+1))\n",
    "\n",
    "\n",
    "def square_nbhd_vec(point: tuple[int, int],\n",
    "                    scale: int,\n",
    "                    x_range: tuple[int, int],\n",
    "                    y_range: tuple[int, int]\n",
    "                    ) -> npt.NDArray:\n",
    "    \"\"\"Returns a 2D array of all coords in a square nbhd about a point\n",
    "\n",
    "    Args:\n",
    "        point: the (x,y) coordinates of the point\n",
    "        scale: the radius of the square\n",
    "        x_range: the least and greatest acceptable x values\n",
    "        y_range: the least and greated acceptable y values\n",
    "\n",
    "    Returns:\n",
    "        An array A of shape (n*m, 2) where n = x_range[1] - x_range[0] + 1\n",
    "        and m = y_range[1] - y_range[0] + 1, whose rows are precisely the\n",
    "        elements of square_nbhd(point, scale, x_range, y_range).\n",
    "    \"\"\"\n",
    "    x, y = point\n",
    "    x_min, x_max = x_range\n",
    "    y_min, y_max = y_range\n",
    "    if x_max < x_min or y_max < y_min:\n",
    "        return np.empty((0,2))\n",
    "    x_min = max(x_min, x - scale)\n",
    "    x_max = min(x_max, x + scale)\n",
    "    y_min = max(y_min, y - scale)\n",
    "    y_max = min(y_max, y + scale)\n",
    "    return cartesian_product(np.arange(x_min, x_max + 1),\n",
    "                             np.arange(y_min, y_max + 1))\n",
    "\n",
    "\n",
    "def extract_classifications(confidence_matrix: npt.NDArray,\n",
    "                            threshold: float\n",
    "                            ) -> dict[tuple[int, int], int]:\n",
    "    \"\"\"Extracts a dictionary of all spot classifications given the threshold.\n",
    "\n",
    "    Args:\n",
    "        confidence_matrix:\n",
    "            A matrix X such that X[i, j, s, c] is the confidence that the\n",
    "            cell type of spot (i, j) is c at scale s.\n",
    "        threshold:\n",
    "            The confidence threshold.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary d such that (i, j) is in d if and only if there is some\n",
    "        scale s and cell type c so that confidence_matrix[i, j, s, c] >= threshold.\n",
    "        Moreover, d[x,y] is the value of c corresponding to the lowest such\n",
    "        value of s.\n",
    "    \"\"\"\n",
    "    confident = zip(*np.where(confidence_matrix >= threshold))\n",
    "    confident = cast(Iterator[tuple[int, int, int, int]], confident)\n",
    "\n",
    "    classifications: dict[tuple[int, int], int] = {}\n",
    "\n",
    "    for i, j, _, cell_type in confident:\n",
    "        if (i, j) not in classifications:\n",
    "            classifications[i, j] = cell_type\n",
    "\n",
    "    return classifications\n",
    "\n",
    "\n",
    "def extract_image(confidence_matrix: npt.NDArray,\n",
    "                  threshold: float\n",
    "                  ) -> npt.NDArray:\n",
    "    classifications = extract_classifications(confidence_matrix, threshold)\n",
    "\n",
    "    image = np.empty(confidence_matrix.shape[:2])\n",
    "    image[:] = np.nan\n",
    "\n",
    "    for (i, j), c in classifications.items():\n",
    "        image[i, j] = c\n",
    "\n",
    "    return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionGrid:\n",
    "    \"\"\"A spatial grid equipped with gene expressions.\n",
    "\n",
    "    An ExpressionGrid encapsulates a 2D grid. For each coordinate (x,y) in the\n",
    "    grid, we have a corresponding gene expression vector where each entry\n",
    "    counts the number of reads of its corresponding gene.\n",
    "\n",
    "    Attributes:\n",
    "        x_min: The smallest x coordinate in the grid.\n",
    "        y_min: The smallest y coordinate in the grid.\n",
    "        x_max: The largest x coordinate in the grid.\n",
    "        y_max: The largest y coordinate in the grid.\n",
    "        height: The height of the grid.\n",
    "        width: The width of the grid.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 table,\n",
    "                 genes: Sequence[str],\n",
    "                 gene_col: str = \"gene\",\n",
    "                 count_col: str = \"count\"\n",
    "                 ):\n",
    "        \"\"\"Inits grid with expression readingsfrom a dataframe.\n",
    "\n",
    "        Args:\n",
    "            table: A dataframe of spot-level gene counts.\n",
    "                Each row in the dataframe corresponds to a reading of one\n",
    "                gene at one spot.\n",
    "                Columns:\n",
    "                    x: The x coordinate of the reading.\n",
    "                    y: The y coordinate of the reading.\n",
    "                    {gene_col}: The gene detected by the reading.\n",
    "                    {count_col}: The number of transcripts measured.\n",
    "            genes:\n",
    "                A full list of all genes under consideration, in order. This\n",
    "                should match the list of genes used for other CountData\n",
    "                intended to be compared with this sample.\n",
    "            gene_col:\n",
    "                A string labelling the column containing gene names.\n",
    "            count_col:\n",
    "                A string labelling the column containing transcript counts.\n",
    "        \"\"\"\n",
    "        self.x_min, self.x_max = table.x.min(), table.x.max()\n",
    "        self.y_min, self.y_max = table.y.min(), table.y.max()\n",
    "        self.height: int = self.x_max - self.x_min + 1\n",
    "        self.width: int = self.y_max - self.y_min + 1\n",
    "        num_genes = len(genes)\n",
    "        matrix = sparse.lil_matrix(((self.height) * (self.width),\n",
    "                                   num_genes)\n",
    "                                   )\n",
    "        for row in table.itertuples():\n",
    "            matrix[self._flatten_coords(row.x, row.y),\n",
    "                   genes.index(getattr(row, gene_col))\n",
    "                   ] = getattr(row, count_col)\n",
    "        self.matrix = matrix.tocsc()\n",
    "        self.num_genes = cast(int, num_genes)\n",
    "\n",
    "    def rows(self) -> range:\n",
    "        \"\"\"Returns a range of all row indices in the grid.\"\"\"\n",
    "        return range(self.x_min, self.x_max+1)\n",
    "\n",
    "    def cols(self) -> range:\n",
    "        \"\"\"Returns a range of all column indices in the grid.\"\"\"\n",
    "        return range(self.y_min, self.y_max+1)\n",
    "\n",
    "    def _flatten_coords(self, i: int, j: int) -> int:\n",
    "        return self.width * (i - self.x_min) + (j - self.y_min)\n",
    "\n",
    "    def _flatten_coords_vec(self, coords) -> npt.ArrayLike:\n",
    "        return ((self.width, 1) * (coords - (self.x_min, self.y_min))).sum(axis=1)\n",
    "\n",
    "    def expression(self, *coords: tuple[(int, int)]) -> sparse.spmatrix:\n",
    "        \"\"\"The total expression at these coordinates in the grid\"\"\"\n",
    "        return self.matrix[list(map(lambda p: self._flatten_coords(*p),\n",
    "                                    coords\n",
    "                                    ))].sum(axis=0)\n",
    "\n",
    "    def expression_vec(self, coords: npt.NDArray) -> sparse.spmatrix:\n",
    "        flattened = self._flatten_coords_vec(coords)\n",
    "        return self.matrix[flattened].sum(axis=0)\n",
    "\n",
    "    def square_nbhd(self,\n",
    "                    i: int,\n",
    "                    j: int,\n",
    "                    scale: int\n",
    "                    ) -> Iterator[tuple[int, int]]:\n",
    "        \"\"\"All coordinates (x,y) in the grid such that d(x,i), d(y-j) <= scale\"\"\"\n",
    "        return square_nbhd((i, j), scale, (self.x_min, self.x_max),\n",
    "                           (self.y_min, self.y_max))\n",
    "\n",
    "    def square_nbhd_vec(self, i: int, j: int, scale: int) -> npt.NDArray:\n",
    "        return square_nbhd_vec((i, j), scale, (self.x_min, self.x_max),\n",
    "                               (self.y_min, self.y_max))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Worker(Process):\n",
    "\n",
    "#     def __init__(self,\n",
    "#                  grid: ExpressionGrid,\n",
    "#                  min_scale: int,\n",
    "#                  max_scale: int,\n",
    "#                  classifier: Classifier,\n",
    "#                  job_queue: Queue,\n",
    "#                  res_queue: Queue,\n",
    "#                  procid: int,\n",
    "#                  verbose: bool\n",
    "#                  ):\n",
    "#         super().__init__()\n",
    "#         self.grid = grid\n",
    "#         self.min_scale = min_scale\n",
    "#         self.max_scale = max_scale\n",
    "#         self.classifier = classifier\n",
    "#         self.job_queue = job_queue\n",
    "#         self.res_queue = res_queue\n",
    "#         self.procid = procid\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     def run(self):\n",
    "#         simplefilter(action='ignore', category=FutureWarning)\n",
    "#         if self.verbose:\n",
    "#             print(f'Worker {self.procid} started')\n",
    "\n",
    "#         num_classes = len(self.classifier.classes)\n",
    "\n",
    "#         cols = list(self.grid.cols())\n",
    "#         num_scales = self.max_scale - self.min_scale + 1\n",
    "#         exprs = np.zeros((num_scales, self.grid.num_genes))\n",
    "#         a =0\n",
    "#         print('1',len(self.job_queue))\n",
    "#         for i, col_values in iter(self.job_queue.get, None):\n",
    "#             a+=1\n",
    "#             if self.verbose:\n",
    "#                 print(f\"Worker {self.procid} got job {i}\")\n",
    "#             for col_index in col_values:\n",
    "#                 j = cols[col_index]\n",
    "#                 for scale in range(self.min_scale, self.max_scale + 1):\n",
    "#                     nbhd = self.grid.square_nbhd_vec(i, j, scale)\n",
    "#                     expr = self.grid.expression_vec(nbhd)\n",
    "#                     exprs[scale - self.min_scale] = expr\n",
    "\n",
    "#                 first_nonzero = densetools.first_nonzero_1d(exprs.sum(axis=1))\n",
    "\n",
    "#                 probs = np.empty((num_scales, num_classes))\n",
    "#                 probs[:] = -1\n",
    "\n",
    "#                 if 0 <= first_nonzero < num_scales:\n",
    "#                     to_classify = np.vstack(exprs[first_nonzero:])  # pyright: ignore # noqa: E501\n",
    "\n",
    "#                     all_confidences = self.classifier.classify(to_classify)\n",
    "\n",
    "#                     probs[first_nonzero:] = all_confidences\n",
    "\n",
    "#                     # sample_confidences = np.max(all_confidences, axis=1)\n",
    "\n",
    "#                     # first_confident = utf1st.find_1st(sample_confidences,\n",
    "#                     #                                   self.threshold,\n",
    "#                     #                                   utf1st.cmp_larger_eq)\n",
    "\n",
    "#                     # if 0 <= first_confident < num_scales - first_nonzero:\n",
    "#                     #     sample_probs = all_confidences[first_confident]\n",
    "#                     #     index = np.argmax(sample_probs)\n",
    "#                     #     result = classifier.classes[index]\n",
    "#                     #     scale = first_confident + first_nonzero + self.min_scale\n",
    "#                     # else:\n",
    "#                     #     result = scale = None\n",
    "#                     # self.res_queue.put((i, j, result, scale))\n",
    "#                 self.res_queue.put((i, j, probs.tolist()))\n",
    "#                 print()\n",
    "#         self.res_queue.put(None)\n",
    "#         if self.verbose:\n",
    "#             print(f'Worker {self.procid} finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job(grid, min_scale, max_scale, classifier):\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "    num_classes = len(classifier.classes)\n",
    "    cols = list(grid.cols())\n",
    "    num_scales = max_scale - min_scale + 1\n",
    "    exprs = np.zeros((num_scales, grid.num_genes))\n",
    "    col_values = 0\n",
    "    res = []\n",
    "    #grid row를 i로, \n",
    "    for i, col_values in iter(grid):\n",
    "        for col_index in col_values:\n",
    "            j = cols[col_index]\n",
    "            for scale in range(min_scale, max_scale + 1):\n",
    "                nbhd = grid.square_nbhd_vec(i, j, scale)\n",
    "                expr = grid.expression_vec(nbhd)\n",
    "                exprs[scale - min_scale] = expr\n",
    "\n",
    "            first_nonzero = densetools.first_nonzero_1d(exprs.sum(axis=1))\n",
    "\n",
    "            probs = np.empty((num_scales, num_classes))\n",
    "            probs[:] = -1\n",
    "\n",
    "            if 0 <= first_nonzero < num_scales:\n",
    "                to_classify = np.vstack(exprs[first_nonzero:])  # pyright: ignore # noqa: E501\n",
    "\n",
    "                all_confidences = classifier.classify(to_classify)\n",
    "\n",
    "                probs[first_nonzero:] = all_confidences\n",
    "                res.append((i, j, np.array(probs).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_job(grid, min_scale, max_scale, classifier, verbose=False):\n",
    "    \"\"\"\n",
    "    Using Serial computing, when performing MPH.\n",
    "    \"\"\"\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "    num_classes = len(classifier.classes)\n",
    "    cols = list(grid.cols())  # 전체 열 인덱스를 리스트로 저장\n",
    "    num_scales = max_scale - min_scale + 1\n",
    "    exprs = np.zeros((num_scales, grid.num_genes))\n",
    "    \n",
    "    # 결과를 저장할 빈 NumPy 배열을 초기화\n",
    "    # (rows, cols, num_scales, num_classes)\n",
    "    res = np.full((len(grid.rows()), len(cols), num_scales, num_classes), -1, dtype=np.float32)\n",
    "    \n",
    "    # grid의 행(row)을 반복 (i는 현재 행의 인덱스)\n",
    "    for i_idx, i in enumerate(grid.rows()):\n",
    "        if verbose:\n",
    "            print(f\"Processing row {i}\")\n",
    "\n",
    "        for col_index in range(len(cols)):\n",
    "            j = cols[col_index]  \n",
    "\n",
    "            # 스케일 범위에 따라 각 (i, j)에 대한 이웃(nbhd) 계산\n",
    "            for scale in range(min_scale, max_scale + 1):\n",
    "                nbhd = grid.square_nbhd_vec(i, j, scale)  # 이웃 벡터 가져오기\n",
    "                expr = grid.expression_vec(nbhd)  # 이웃에서 유전자 발현 값 가져옴\n",
    "                exprs[scale - min_scale] = expr  # 스케일에 따른 발현 값을 저장\n",
    "\n",
    "            first_nonzero = densetools.first_nonzero_1d(exprs.sum(axis=1))\n",
    "\n",
    "            if 0 <= first_nonzero < num_scales:\n",
    "                to_classify = np.vstack(exprs[first_nonzero:])\n",
    "                all_confidences = classifier.classify(to_classify)\n",
    "                probs = np.empty((num_scales, num_classes))\n",
    "                probs[:] = -1\n",
    "                probs[first_nonzero:] = all_confidences\n",
    "\n",
    "                res[i_idx, col_index] = probs\n",
    "\n",
    "    if verbose:\n",
    "        print(\"All jobs completed.\")\n",
    "    print('res shape:', res.shape)\n",
    "    #res = res.transpose(2,0,1,3)\n",
    "\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CountGrid(CountTable):\n",
    "    \"\"\"A spatial transcriptomics object with associated methods.\n",
    "\n",
    "    Attributes:\n",
    "        grid: An expression grid.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Inits spatial data with values from a dataframe.\"\"\"\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.generate_expression_grid()\n",
    "        self.height, self.width = self.grid.height, self.grid.width\n",
    "\n",
    "    @classmethod\n",
    "    def from_coord_table(cls, table, **kwargs):\n",
    "        x_coords = range(table.x.min(), table.x.max() + 1)\n",
    "        y_coords = range(table.y.min(), table.y.max() + 1)\n",
    "\n",
    "        coords = itertools.product(x_coords, y_coords)\n",
    "        samples = map(combine_coords, coords)\n",
    "\n",
    "        new_table = table.copy()\n",
    "        new_table['sample'] = new_table.apply(lambda row: f'{row.x},{row.y}',\n",
    "                                              axis=1)\n",
    "\n",
    "        count_grid = cls(new_table, samples=list(samples), **kwargs)\n",
    "        samples = count_grid.samples\n",
    "        x_coords = {sample: first_coord(sample) for sample in samples}\n",
    "        y_coords = {sample: second_coord(sample) for sample in samples}\n",
    "        count_grid.add_metadata('x', x_coords)\n",
    "        count_grid.add_metadata('y', y_coords)\n",
    "        return count_grid\n",
    "\n",
    "    def pseudobulk(self) -> npt.NDArray:\n",
    "        return np.array(self.grid.matrix.sum(axis=0))[0]\n",
    "\n",
    "    def count_matrix(self) -> npt.NDArray:\n",
    "        # It's tempting to try and do something clever with numpy or pandas\n",
    "        # here. There be dragons.\n",
    "        x_min = self.table.x.min()\n",
    "        y_min = self.table.y.min()\n",
    "        count_matrix = np.zeros((self.width, self.height))\n",
    "        counts = self.table.groupby(['x', 'y']).sum().reset_index()\n",
    "        count_index = self.table.columns.get_loc(self.count_col)\n",
    "        for row in counts.itertuples():\n",
    "            count_matrix[row.y-y_min, row.x-x_min] += row[count_index]\n",
    "        return count_matrix\n",
    "\n",
    "    def density_mask(self, radius: int, threshold: int) -> npt.NDArray:\n",
    "        return densetools.density_hull(self.count_matrix(), radius, threshold)\n",
    "\n",
    "    def generate_expression_grid(self):\n",
    "        self.grid = ExpressionGrid(self.table,\n",
    "                                   genes=self.genes,\n",
    "                                   gene_col=self.gene_col,\n",
    "                                   count_col=self.count_col\n",
    "                                   )\n",
    "\n",
    "\n",
    "    def annotate(self,\n",
    "                 confidence_matrix: npt.NDArray,\n",
    "                 threshold: float,\n",
    "                 labels: tuple[str, ...],\n",
    "                 column_label: str = \"cell type\"):\n",
    "\n",
    "        classifications = extract_classifications(confidence_matrix, threshold)\n",
    "        x_min, y_min = self.grid.x_min, self.grid.y_min\n",
    "        to_add = {combine_coords((x+x_min, y+y_min)): labels[c]\n",
    "                  for (x, y), c in classifications.items()\n",
    "                  }\n",
    "\n",
    "        self.add_metadata(column_label, to_add)\n",
    "\n",
    "    def classify_parallel(self,\n",
    "                        classifier: Classifier,\n",
    "                        min_scale: int,\n",
    "                        max_scale: int,\n",
    "                        outfile: str,\n",
    "                        mask: npt.NDArray | None = None,\n",
    "                        num_proc: int = 1,\n",
    "                        verbose: bool = False\n",
    "                        ):\n",
    "\n",
    "        outfile += '' if outfile[-4:] == '.npy' else '.npy'\n",
    "        shape = (self.grid.height,\n",
    "                self.grid.width,\n",
    "                max_scale - min_scale + 1,\n",
    "                len(classifier.classes)\n",
    "                )\n",
    "        result = np.lib.format.open_memmap(outfile, dtype=np.float32,\n",
    "                                        mode='w+', shape=shape)\n",
    "        result[:] = np.nan\n",
    "        result.flush()\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.T\n",
    "            if mask.shape != (self.height, self.width):\n",
    "                raise ValueError(f'Mask has shape {mask.shape} but expected {(self.height, self.width)}')\n",
    "            col_values = [[j for j in range(self.width) if mask[i, j] == 1] for i in range(self.height)]\n",
    "        else:\n",
    "            col_values = [list(range(self.width)) for _ in range(self.height)]\n",
    "\n",
    "\n",
    "        job_results = process_job(self.grid, min_scale, max_scale, classifier, verbose=verbose)\n",
    "        # (7, 100, 100, 2)의 첫 번째 차원인 7에 대해 반복하면서 각 (100, 100, 2) 배열을 처리\n",
    "        print(job_results[0][0]) #[[a,b]*7]\n",
    "        for i in range(job_results.shape[0]):  # 첫 번째 차원인 100 (행의 개수)\n",
    "            for j in range(job_results.shape[1]):\n",
    "                probs = job_results[i, j]\n",
    "                result[i - self.grid.x_min, j - self.grid.y_min] = probs\n",
    "        '''\n",
    "        for radius in range(job_results.shape[0]):\n",
    "            grid_per_r = job_results[radius]  # (100, 100, 2) 배열\n",
    "            print(grid_per_r[0][0])\n",
    "            for i in range(grid_per_r.shape[0]):  # 첫 번째 차원인 100 (행의 개수)\n",
    "                for j in range(grid_per_r.shape[1]):  # 두 번째 차원인 100 (열의 개수)\n",
    "                    probs = grid_per_r[i, j]  # 현재 위치 (i, j)의 확률값 가져오기, (2,) 형태\n",
    "                    result[i - self.grid.x_min, j - self.grid.y_min] = probs\n",
    "'''\n",
    "        print(result.shape)\n",
    "        result.flush()\n",
    "        if verbose:\n",
    "            print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix shape (2000, 769)\n",
      "res shape: (100, 100, 7, 2)\n",
      "[[0.9192161  0.0807839 ]\n",
      " [0.92415    0.07584998]\n",
      " [0.8363716  0.16362838]\n",
      " [0.89124316 0.10875686]\n",
      " [0.81830484 0.18169515]\n",
      " [0.8617691  0.13823092]\n",
      " [0.9077422  0.09225779]]\n",
      "(100, 100, 7, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from scipy import io\n",
    "\n",
    "\n",
    "from countdata import CountMatrix\n",
    "from classifier import SVCClassifier, train_from_countmatrix\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename) as f:\n",
    "        return [line.rstrip() for line in f]\n",
    "\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename) as f:\n",
    "        return [line.rstrip() for line in f]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load single-cell reference\n",
    "    mtx = io.mmread('scmatrix.mtx').T  # (2000,796)\n",
    "    genes = readfile('scgenes.txt')  # (796)\n",
    "    labels = readfile('sclabels.txt')  # (2000)\n",
    "\n",
    "    # Create TopACT object\n",
    "    sc = CountMatrix(mtx, genes=genes)\n",
    "    sc.add_metadata(\"celltype\", labels)\n",
    "\n",
    "    # Train local classifier\n",
    "    clf = SVCClassifier()\n",
    "    # clf = KNNClassifier()\n",
    "    # clf = PCASVCClassifier()\n",
    "    # clf = SVD_SVCClassifier()\n",
    "    train_from_countmatrix(clf, sc, \"celltype\")  # SVM train using sc\n",
    "\n",
    "    # Load spatial data\n",
    "    df = pd.read_csv('spatial.csv')\n",
    "\n",
    "    # Create CountGrid object from coord table\n",
    "    sd = CountGrid.from_coord_table(df, genes=genes, count_col=\"counts\", gene_col=\"gene\")\n",
    "\n",
    "    # Classify\n",
    "    sd.classify_parallel(clf, min_scale=3, max_scale=9, num_proc=1, outfile='outfile.npy')\n",
    "\n",
    "    confidence_mtx = np.load('outfile.npy')\n",
    "\n",
    "    annotations = extract_image(confidence_mtx, 0.5)\n",
    "\n",
    "    np.savetxt(\"demo-output.txt\", annotations, fmt='%1.f')\n",
    "\n",
    "    plt.imshow(annotations, interpolation='None')\n",
    "    plt.savefig('demo-output.png')\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #mp.set_start_method('fork')\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import classifier\n",
    "\n",
    "# classifier 모듈 재로드\n",
    "importlib.reload(classifier)\n",
    "\n",
    "# 이제 임포트 시도\n",
    "from classifier import SVCClassifier, train_from_countmatrix, KNNClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# topact 경로를 PYTHONPATH에 추가\n",
    "topact_path = \"/Users/hongseohyeong/Desktop/TopACT_copy/topact\"\n",
    "if topact_path not in sys.path:\n",
    "    sys.path.append(topact_path)\n",
    "\n",
    "# 환경변수에 경로 추가 (필요하면)\n",
    "os.environ['PYTHONPATH'] = topact_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
